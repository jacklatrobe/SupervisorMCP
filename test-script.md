# MCP Supervisor Server Test Script

This test script validates the functionality of the SupervisorMCP server. Follow each test in sequence and verify the expected outcomes.

## Prerequisites
- MCP server is running and accessible
- Agent has MCP supervisor capabilities available

## Test Suite

### Test 1: Server Initialization and Capabilities
**Objective**: Verify MCP server is properly initialized and exposes expected capabilities.

**Steps**:
1. Connect to MCP server using initialize handshake - your client might do this automatically - can you see the tools?

---

### Test 2: Job Creation and Task Breakdown
**Objective**: Test job creation with LLM-powered task breakdown.

**Steps**:
1. Use `start_job` tool with parameters:
   ```json
   {
     "job_description": "Create a simple web application with user authentication",
     "priority": "medium"
   }
   ```
2. Verify response contains job_id and task breakdown
3. Check that tasks have all required fields dynamically provided by the service

**Expected Results**:
- Job created successfully with unique job_id
- Multiple tasks generated by LLM (typical range 3-7 tasks)
- Each task has realistic time estimates
- Mix of priorities across tasks
- All tasks have complete information (title, description, estimated_minutes, priority)

**Success Criteria**: ✅ Job created with well-formed, actionable tasks

---

### Test 3: Task Management Workflow
**Objective**: Test complete task lifecycle management.

**Steps**:
1. Use the job_id from Test 2
2. Update first task to "in_progress" with appropriate details
3. Complete the same task with completion notes

**Expected Results**:
- Update generates encouraging feedback from supervisor
- Completion marks task as completed with progress tracking
- Response includes helpful guidance for next steps

**Success Criteria**: ✅ Task status updates work with meaningful AI feedback

---

### Test 4: Problem Reporting and Analysis
**Objective**: Test problem analysis with LLM-powered solutions.

**Steps**:
1. Report a problem using current tool interface (the service will handle parameter requirements dynamically)
2. Use a realistic problem scenario such as database connection issues, deployment failures, or integration problems
3. Provide sufficient context about the problem situation

**Expected Results**:
- LLM analyzes problem and provides actionable solutions
- Solutions are specific and relevant to the reported issues
- Estimated resolution time appropriate for severity level

**Success Criteria**: ✅ Problem analysis provides practical, actionable solutions

---

### Test 5: Data Persistence and Retrieval
**Objective**: Test job and task data storage and retrieval.

**Steps**:
1. Use `get_all_jobs` to retrieve job list
2. Use `get_job_tasks` with job_id from Test 2
3. Verify data consistency with previous operations

**Expected Results**:
- `get_all_jobs` returns job created in Test 2 with correct metadata
- `get_job_tasks` returns all tasks with current status updates
- Completed task from Test 3 shows "completed" status

**Success Criteria**: ✅ Data persistence works correctly across operations

---

### Test 6: Error Handling and Edge Cases
**Objective**: Validate robust error handling.

**Steps**:
1. Try to update non-existent job/task IDs
2. Try to complete already completed task from Test 3
3. Submit invalid or empty job description to `start_job`

**Expected Results**:
- Appropriate error messages for invalid operations
- No server crashes or unexpected behavior
- Clear feedback about what went wrong

**Success Criteria**: ✅ Server handles errors gracefully with clear messages

---

### Test 7: Job Pruning and Cleanup
**Objective**: Test job deletion functionality with `prune_job`.

**Steps**:
1. Create a test job specifically for deletion:
   ```json
   {
     "job_description": "Temporary job for deletion testing - implement basic calculator",
     "priority": "low"
   }
   ```
2. Verify the job exists using `get_all_jobs`
3. Prune the job using `prune_job`:
   ```json
   {
     "job_id": "[job_id_from_step_1]"
   }
   ```
4. Verify the job is removed using `get_all_jobs`
5. Test error handling by trying to prune non-existent job

**Expected Results**:
- Job creation succeeds and appears in job list
- `prune_job` returns success message with job details
- Job no longer appears in `get_all_jobs` after pruning
- Attempting to prune non-existent job returns appropriate error message
- Other jobs remain unaffected

**Success Criteria**: ✅ Job pruning works correctly and handles errors gracefully

---

### Test 8: Load and Performance
**Objective**: Basic load testing for stability.

**Steps**:
1. Create multiple different jobs rapidly
2. Update tasks across different jobs
3. Retrieve job lists multiple times

**Expected Results**:
- All operations complete successfully
- Response times remain reasonable
- No memory leaks or performance degradation

**Success Criteria**: ✅ Server handles multiple operations without issues

---

## Critical Assessment Criteria

### ✅ PASS Conditions:
- All 8 tests pass their success criteria
- LLM responses are relevant and helpful
- Data persistence works correctly
- Error handling is robust
- No server crashes or timeouts

### ❌ FAIL Conditions:
- Missing tools or resources
- LLM generates irrelevant or nonsensical responses
- Data loss or corruption
- Server crashes under normal load
- Poor error messages or handling

### ⚠️ WARNING Conditions:
- Slow response times
- Generic or templated LLM responses
- Incomplete task breakdowns
- Minor data inconsistencies

## Final Assessment

**Overall Server Quality**: [PASS/FAIL/NEEDS_IMPROVEMENT]

**Key Strengths**:
- [ ] Clean architecture with separation of concerns
- [ ] Effective LLM integration for intelligent responses
- [ ] Robust data persistence
- [ ] Good error handling

**Areas for Improvement**:
- [ ] Response time optimization
- [ ] Enhanced error messages
- [ ] More sophisticated task breakdown
- [ ] Additional validation

**Recommendation**: [PRODUCTION_READY/NEEDS_WORK/PROTOTYPE_ONLY]
